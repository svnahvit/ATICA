# Tabla de Contenidos

## 1. Algoritmo para generar la memoria
## 2. Introducción a Pandas, Matplotlib y Plotly.
### 2.1 Motivación
### 2.2 Importamos las librerías necesarias
### 2.3 Definimos las funciones de las que vamos a hacer uso posteriormente
### 2.4 Lectura de datos
### 2.5 Añadimos los datos del día 2022-09-09
### 2.6 Limpieza de datos
### 2.7 Visualización de datos y relaciones entre distintas variables
#### 2.7.1 Conexiones VS Hora del día
#### 2.7.2 Conexiones VS Días de la semana
#### 2.7.3 Conexiones VS Meses
### 2.8 Normalización de variables numéricas

## 3. Análisis exploratorio y preprocesamiento de los datos
### 3.1 Motivación
### 3.2 Introducción teórica del árbol de decisión
### 3.3 Datos con los que trabajaremos
### 3.4 Importamos librerías necesarias
### 3.5 Lectura de datos
### 3.6 Análisis exploratorio de datos
#### 3.6.1 Tipado de los datos y cantidad de datos ausentes
#### 3.6.2 Datos con ruido
#### 3.6.3 Variables sin sentido o con datos incorrectos
#### 3.6.4 Varianza cercana a cero
#### 3.6.5 Variables idénticas
### 3.7 Preprocesamiento para el entrenamiento
#### 3.7.1 Elección de la variable de salida
#### 3.7.2 Desbalanceo
#### 3.7.3 Oversampling Básico
#### 3.7.4 Undersampling Básico
#### 3.7.5 ROSE
#### 3.7.6 Reducción de coste de memoria
#### 3.7.7 SMOTE
#### 3.7.8 SMOTEENN
#### 3.7.9 SMOTE y Undersampling
#### 3.7.10 Correlación de las variables
#### 3.7.11 Correlación entre las variables numéricas
#### 3.7.12 Correlación entre las variables categóricas y binarias
#### 3.7.13 Reducción de dimensionalidad
#### 3.7.14 PCA
#### 3.7.15 RFE
### 3.8 Ideas pendientes

## 4. Comparación de Modelos de Predicción
### 4.1 Motivación
### 4.2 Preprocesamiento de los datos
#### 4.2.1 Importamos librerías necesarias
#### 4.2.2 Lectura de datos
#### 4.2.3 DataFrame numérico con variable de salida NOTA_NUMERICA
#### 4.2.4 DataFrame binario con variable de salida PRESENTADO
### 4.3 Conceptos previos necesarios
#### 4.3.1 Overfitting
#### 4.3.2 Underfitting
#### 4.3.3 Variabilidad y Trade-Off entre sesgo y varianza
#### 4.3.4 Métricas de evaluación de modelos de regresión
#### 4.3.5 Métricas de evaluación de modelos de clasificación
#### 4.3.6 Hiperparámetros
#### 4.3.7 Elección de hiperparámetros
### 4.4 Modelos de predicción
#### 4.4.1 Regresión lineal
#### 4.4.2 Regresión logística
#### 4.4.3 Naïve Bayes
#### 4.4.4 Árbol de decisión
#### 4.4.5 Bagging y Boosting
#### 4.4.6 Random Forest
#### 4.4.7 Gradient Boosting Classifier
#### 4.4.8 XGBoost
#### 4.4.9 Redes neuronales
#### 4.4.10 Transformers
### 4.5 Mejorando los resultados

## 5. Análisis de Sentimientos
### 5.1 Motivación
### 5.2 Vías de obtención de datos
#### 5.2.1 Uso de API
#### 5.2.2 Web Scraping
### 5.3 Análisis de Sentimientos
#### 5.3.1 Pysentimiento
### 5.4 Propuestas de otras ideas
#### 5.4.1 Detección de Discurso de Odio
#### 5.4.2 Análisis de emociones

## 6. Agradecimientos
## 7. Referencias
